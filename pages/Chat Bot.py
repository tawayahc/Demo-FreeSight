from gtts import gTTS
from io import BytesIO
from audio_recorder_streamlit import audio_recorder
import streamlit as st
import openai
import speech_recognition as sr

openai.api_key = "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"
recognizer = sr.Recognizer()

messages = [
    {"role": "system", "content": "You are a kind helpful assistant."}
]

def listen(audio_bytes):
    try:
        audio_data = sr.AudioData(audio_bytes, sample_rate=44100, sample_width=4)
        text = recognizer.recognize_google(audio_data, language='th-TH')
        return text
    except sr.UnknownValueError:
        st.write("‚ùå‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏û‡∏π‡∏î‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
    except sr.RequestError as e:
        st.write("‚ùå‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏û‡∏π‡∏î‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á: " + e)
    return ""

def generate_response(prompt):
    response = openai.Completion.create(
        engine = "text-davinci-003",
        prompt = f"{prompt}\n\nLanguage: th",
        max_tokens = 500,
        n = 1,
        stop = None,
        temperature = 0.5
    )
    return response.choices[0].text.strip()

def chat_gpt_response(speech):
    message = speech
    if message:
        messages.append(
            {"role": "user", "content": message},
        )
        chat = openai.ChatCompletion.create(
            model="gpt-3.5-turbo", messages=messages
        )

    reply = chat.choices[0].message.content
    messages.append({"role": "assistant", "content": reply})

    return reply

def convert_str_to_audio_data(audio_text):
    audio_data = BytesIO()
    tts = gTTS(audio_text, lang = "th")
    tts.write_to_fp(audio_data)

    return audio_data

def ai_assistant(audio_bytes):
    st.divider()
    speech = listen(audio_bytes)
    if speech == "":
        response = "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏û‡∏π‡∏î‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á"
        audio_data = convert_str_to_audio_data(response)

        st.subheader("‡πÄ‡∏™‡∏µ‡∏¢‡∏áüîä")
        st.audio(audio_data)
    else:
        if "‡∏•‡∏≤‡∏Å‡πà‡∏≠‡∏ô" in speech:
            st.write("You said: " + speech)
            response = "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏∞"
            st.write("AI said: " + response)

            audio_data = convert_str_to_audio_data(response)
            st.subheader("‡πÄ‡∏™‡∏µ‡∏¢‡∏áüîä")
            st.audio(audio_data)
        else:
            st.subheader("‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤üí¨")
            st.write("‡∏Ñ‡∏∏‡∏ì: {speech}".format(speech=speech))
            response = generate_response(speech)
            st.write("‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞: {response}".format(response=response))

            audio_data = convert_str_to_audio_data(response)
            st.subheader("‡πÄ‡∏™‡∏µ‡∏¢‡∏áüîä")
            st.audio(audio_data)

st.header("Smart Assistantüí°")
st.divider()
st.subheader("‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏îüé§")
audio_bytes = audio_recorder(text="", icon_size="10x")
if audio_bytes:
    ai_assistant(audio_bytes)